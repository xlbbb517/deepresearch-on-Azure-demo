import asyncio
import os
import logging
from flask import Flask, render_template, request, jsonify, send_file
import json
from typing import Optional
from datetime import datetime
import threading
import queue
from azure.ai.projects.aio import AIProjectClient
from azure.ai.agents.aio import AgentsClient
from azure.ai.agents.models import DeepResearchTool, MessageRole, ThreadMessage
from azure.identity.aio import DefaultAzureCredential
from dotenv import load_dotenv

# local testing
if os.path.exists('.env'):
    load_dotenv()

# æ£€æŸ¥å¿…éœ€çš„ç¯å¢ƒå˜é‡ï¼ˆé™é»˜æ£€æŸ¥ï¼‰
required_env_vars = [
    'AZURE_AI_PROJECT_ENDPOINT',
    'BING_CONNECTION_NAME'
]

# Azureè®¤è¯ç›¸å…³å˜é‡
auth_env_vars = ['AZURE_CLIENT_ID', 'AZURE_CLIENT_SECRET', 'AZURE_TENANT_ID']

missing_vars = [var for var in required_env_vars if not os.environ.get(var)]


auth_vars_configured = all(
    os.environ.get(var) and os.environ.get(var).strip() 
    for var in auth_env_vars
)

# å¦‚æœæœ‰ç¼ºå¤±çš„ç¯å¢ƒå˜é‡ï¼Œç¨‹åºæ— æ³•è¿è¡Œ
if missing_vars:
    # åªåœ¨è¿™ç§æƒ…å†µä¸‹ç«‹å³æ˜¾ç¤ºé”™è¯¯
    print(f"âŒ ç¼ºå°‘ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
    print("è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®è¿™äº›å˜é‡")
    exit(1)

# ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
AZURE_AI_PROJECT_ENDPOINT = os.environ.get('AZURE_AI_PROJECT_ENDPOINT')
BING_CONNECTION_NAME = os.environ.get('BING_CONNECTION_NAME')
DEEP_RESEARCH_MODEL = os.environ.get('DEEP_RESEARCH_MODEL', 'o3-deep-research')
AGENT_MODEL = os.environ.get('AGENT_MODEL', 'gpt-4o')
AGENT_NAME = os.environ.get('AGENT_NAME', 'my-research-agent')
FLASK_HOST = os.environ.get('FLASK_HOST', '127.0.0.1')
FLASK_DEBUG = os.environ.get('FLASK_DEBUG', 'True').lower() == 'true'

# åˆ›å»ºæ—¥å¿—ç›®å½•
if not os.path.exists('logs'):
    os.makedirs('logs')

log_filename = f"logs/simple_web_{datetime.now().strftime('%Y%m%d')}.log"

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_filename, encoding='utf-8')
    ]
)

console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_formatter = logging.Formatter('%(levelname)s - %(message)s')
console_handler.setFormatter(console_formatter)

logger = logging.getLogger(__name__)
logger.addHandler(console_handler)
logger.setLevel(logging.INFO)

# è®¾ç½®ç¬¬ä¸‰æ–¹åº“çš„æ—¥å¿—çº§åˆ«
logging.getLogger('werkzeug').setLevel(logging.ERROR)
logging.getLogger('flask').setLevel(logging.ERROR)
logging.getLogger('azure').setLevel(logging.WARNING)
logging.getLogger('azure.core').setLevel(logging.ERROR)
logging.getLogger('azure.identity').setLevel(logging.ERROR)
logging.getLogger('azure.ai').setLevel(logging.WARNING)
logging.getLogger('urllib3').setLevel(logging.ERROR)
logging.getLogger('aiohttp').setLevel(logging.ERROR)

app = Flask(__name__)
app.config['SECRET_KEY'] = os.environ.get('FLASK_SECRET_KEY', 'deep-research-web-ui-secret-key-2025')

# ç¦ç”¨ Flask çš„è¯·æ±‚æ—¥å¿—
app.logger.setLevel(logging.ERROR)

# å…¨å±€çŠ¶æ€
status = {
    'is_running': False,
    'messages': [],
    'waiting_for_input': False,
    'error': None,
    'result_file': None
}

# æ¶ˆæ¯é˜Ÿåˆ—ç”¨äºçº¿ç¨‹é—´é€šä¿¡
message_queue = queue.Queue()
response_queue = queue.Queue()

def create_research_summary(message: ThreadMessage, filepath: str = "research_summary.md") -> None:
    """åˆ›å»ºç ”ç©¶æ‘˜è¦ - ä¸demoå®Œå…¨ä¸€è‡´"""
    if not message:
        logging.getLogger(__name__).warning("No message content provided, cannot create research summary.")
        return

    with open(filepath, "w", encoding="utf-8") as fp:
        text_summary = "\n\n".join([t.text.value.strip() for t in message.text_messages])
        fp.write(text_summary)

        if message.url_citation_annotations:
            fp.write("\n\n## References\n")
            seen_urls = set()
            for ann in message.url_citation_annotations:
                url = ann.url_citation.url
                title = ann.url_citation.title or url
                if url not in seen_urls:
                    fp.write(f"- [{title}]({url})\n")
                    seen_urls.add(url)

    logging.getLogger(__name__).info(f"ç ”ç©¶æ‘˜è¦å·²å†™å…¥æ–‡ä»¶: {filepath}")

async def fetch_and_print_new_agent_response(
    thread_id: str,
    agents_client: AgentsClient,
    last_message_id: Optional[str] = None,
) -> Optional[str]:
    """è·å–æ–°çš„åŠ©æ‰‹å“åº” - ä¸demoå®Œå…¨ä¸€è‡´"""
    file_logger = logging.getLogger(__name__)
    
    response = await agents_client.messages.get_last_message_by_role(
        thread_id=thread_id,
        role=MessageRole.AGENT,
    )

    if not response or response.id == last_message_id:
        return last_message_id

    response_text = "\n".join(t.text.value for t in response.text_messages)
    
    # æ·»åŠ åˆ°çŠ¶æ€æ¶ˆæ¯åˆ—è¡¨
    status['messages'].append({
        'role': 'assistant',
        'content': response_text,
        'timestamp': datetime.now().isoformat()
    })
    
    # åªè®°å½•åˆ°æ–‡ä»¶
    file_logger.debug(f"æ”¶åˆ°æ–°çš„åŠ©æ‰‹å“åº”ï¼ŒID: {response.id}")
    file_logger.debug(f"åŠ©æ‰‹å“åº”å†…å®¹: {response_text[:200]}...")

    for ann in response.url_citation_annotations:
        file_logger.debug(f"URL Citation: [{ann.url_citation.title}]({ann.url_citation.url})")

    return response.id

async def run_research_session():
    """è¿è¡Œç ”ç©¶ä¼šè¯ - å®Œå…¨æŒ‰ç…§demoçš„main()å‡½æ•°é€»è¾‘"""
    global status
    
    file_logger = logging.getLogger(__name__)
    agent_id_to_delete = None
    thread_id_to_delete = None
    agents_client_for_cleanup = None
    
    try:
        status['is_running'] = True
        status['messages'] = []
        
        # ç­‰å¾…åˆå§‹ä¸»é¢˜
        file_logger.debug("ç­‰å¾…ç”¨æˆ·è¾“å…¥ç ”ç©¶ä¸»é¢˜...")
        initial_topic = message_queue.get()
        
        status['messages'].append({
            'role': 'user',
            'content': initial_topic,
            'timestamp': datetime.now().isoformat()
        })

        logger.info(f"å¼€å§‹ç ”ç©¶ä¼šè¯: {initial_topic}")
        file_logger.info(f"å¼€å§‹ç ”ç©¶ä¼šè¯ï¼Œä¸»é¢˜: {initial_topic}")

        # Use 'async with' to manage the credential lifecycle
        async with DefaultAzureCredential() as credential:
            project_client = AIProjectClient(
                endpoint=AZURE_AI_PROJECT_ENDPOINT,
                credential=credential,
            )
            
            async with project_client:
                try:
                    agents_client = project_client.agents
                    agents_client_for_cleanup = agents_client

                    conn = await project_client.connections.get(name=BING_CONNECTION_NAME)
                    conn_id = conn.id
                    file_logger.debug(f"è·å–åˆ°Bingè¿æ¥ID: {conn_id}")
                    
                    deep_research_tool = DeepResearchTool(
                        bing_grounding_connection_id=conn_id,
                        deep_research_model=DEEP_RESEARCH_MODEL,
                    )

                    agent = await agents_client.create_agent(
                        model=AGENT_MODEL,
                        name=AGENT_NAME,
                        instructions=(
                            "You are a helpful Agent that assists in researching scientific topics. "
                            "First, you should ask clarifying questions to get enough information. "
                            "When you have enough information, use the deep_research tool to provide the final answer. "
                            "When calling the deep_research tool, you MUST follow these rules:\n"
                            "1. Only use 'title' and 'prompt' parameters\n"
                            "2. Ensure all parameter values are properly formatted strings\n"
                            "3. Avoid special characters like unmatched parentheses in parameter values\n"
                            "4. Keep parameter values concise and well-formatted\n"
                            "Example format: deep_research(title=\"Research Title\", prompt=\"Your research question here\")"
                        ),
                        tools=deep_research_tool.definitions,
                    )
                    agent_id_to_delete = agent.id
                    file_logger.info(f"ç ”ç©¶åŠ©æ‰‹å·²åˆ›å»ºï¼ŒID: {agent.id}")

                    thread = await agents_client.threads.create()
                    thread_id_to_delete = thread.id
                    file_logger.info(f"å¯¹è¯çº¿ç¨‹å·²åˆ›å»ºï¼ŒID: {thread.id}")

                    user_message_content = initial_topic
                    last_message_id: Optional[str] = None
                    agent_response_text = ""
                    max_retries = 3
                    current_retries = 0

                    while True:
                        if current_retries >= max_retries:
                            file_logger.error(f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})ï¼Œç»ˆæ­¢ç¨‹åº")
                            break

                        if user_message_content:
                            message = await agents_client.messages.create(
                                thread_id=thread.id,
                                role="user",
                                content=user_message_content,
                            )
                            file_logger.debug(f"æ¶ˆæ¯å·²åˆ›å»ºï¼ŒID: {message.id}")

                        file_logger.debug("æ­£åœ¨å¤„ç†æ¶ˆæ¯...")
                        
                        if "start_research_task" in agent_response_text:
                            file_logger.info("æ£€æµ‹åˆ°ç ”ç©¶ä»»åŠ¡å¼€å§‹æ ‡å¿—ï¼Œå¼ºåˆ¶æ‰§è¡Œå·¥å…·")
                            run = await agents_client.runs.create(
                                thread_id=thread.id, 
                                agent_id=agent.id,
                                tools=deep_research_tool.definitions
                            )
                        else:
                            run = await agents_client.runs.create(thread_id=thread.id, agent_id=agent.id)
                        
                        while run.status in ("queued", "in_progress"):
                            await asyncio.sleep(5)
                            run = await agents_client.runs.get(thread_id=thread.id, run_id=run.id)
                            
                            new_last_message_id = await fetch_and_print_new_agent_response(
                                thread_id=thread.id,
                                agents_client=agents_client,
                                last_message_id=last_message_id,
                            )
                            if new_last_message_id != last_message_id:
                                last_message_id = new_last_message_id
                                latest_message = await agents_client.messages.get(thread_id=thread.id, message_id=last_message_id)
                                agent_response_text = "\n".join(t.text.value for t in latest_message.text_messages)

                            file_logger.debug(f"è¿è¡ŒçŠ¶æ€: {run.status}")

                        file_logger.info(f"è¿è¡Œå®Œæˆï¼ŒçŠ¶æ€: {run.status}")

                        if run.status == "completed":
                            current_retries = 0

                        if run.status == "failed":
                            error_code = run.last_error.get('code') if run.last_error else None
                            error_message = run.last_error.get('message', '') if run.last_error else ''
                            
                            current_retries += 1
                            file_logger.warning(f"è¿è¡Œå¤±è´¥ï¼Œé‡è¯• {current_retries}/{max_retries}")
                            file_logger.warning(f"é”™è¯¯è¯¦æƒ…: {error_message}")

                            if error_code == 'tool_server_error':
                                if 'too many values to unpack' in error_message:
                                    correction_message = "You previously failed to call the deep_research tool because you provided the wrong number of parameters. Please try again, and ONLY use the 'title' and 'prompt' parameters for the tool call. Make sure the parameter values are properly formatted strings without special characters."
                                elif 'could not be parsed' in error_message or 'unmatched' in error_message:
                                    correction_message = (
                                        "You previously failed to call the deep_research tool due to a parsing error. "
                                        "Please ensure you:\n"
                                        "1. Only use 'title' and 'prompt' parameters\n"
                                        "2. Properly format all parameter values as strings\n"
                                        "3. Avoid special characters like unmatched parentheses, quotes, or brackets\n"
                                        "4. Use simple, clean text for both title and prompt\n"
                                        "Please try calling the tool again with corrected formatting."
                                    )
                                else:
                                    correction_message = (
                                        "There was an error with the deep_research tool. Please try again with:\n"
                                        "- Only 'title' and 'prompt' parameters\n"
                                        "- Simple, clean text without special formatting\n"
                                        "- Proper string formatting"
                                    )
                                
                                await agents_client.messages.create(
                                    thread_id=thread.id,
                                    role="user",
                                    content=correction_message
                                )
                                user_message_content = None 
                                agent_response_text = ""
                                continue
                            elif error_code == 'server_error' and 'Sorry, something went wrong' in error_message:
                                file_logger.info("ä¸´æ—¶æœåŠ¡å™¨é”™è¯¯ï¼Œç›´æ¥é‡è¯•")
                                user_message_content = None 
                                agent_response_text = ""
                                continue
                            else:
                                file_logger.error(f"è¿è¡Œå¤±è´¥ï¼Œä¸å¯æ¢å¤çš„é”™è¯¯: {run.last_error}")
                                break
                    
                        final_message = await agents_client.messages.get_last_message_by_role(
                            thread_id=thread.id, role=MessageRole.AGENT
                        )

                        if final_message:
                            agent_response_text = "\n".join(t.text.value for t in final_message.text_messages)
                            if final_message.id != last_message_id:
                                file_logger.debug("æ”¶åˆ°æœ€ç»ˆåŠ©æ‰‹å“åº”")
                                last_message_id = final_message.id

                        if final_message and final_message.url_citation_annotations:
                            logger.info("ç ”ç©¶å®Œæˆï¼Œç”ŸæˆæŠ¥å‘Šä¸­...")
                            file_logger.info("æ‰¾åˆ°å¼•ç”¨èµ„æ–™ï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
                            timestamp = int(datetime.now().timestamp())
                            result_file = f"research_summary_{timestamp}.md"
                            create_research_summary(final_message, filepath=result_file)
                            status['result_file'] = result_file
                            status['waiting_for_input'] = False
                            break
                        
                        if "start_research_task" not in agent_response_text:
                            status['waiting_for_input'] = True
                            logger.info("ç­‰å¾…ç”¨æˆ·è¡¥å……ä¿¡æ¯")
                            file_logger.info("ç­‰å¾…ç”¨æˆ·è¡¥å……ä¿¡æ¯...")
                            
                            # ç­‰å¾…ç”¨æˆ·è¾“å…¥
                            try:
                                user_message_content = message_queue.get(timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
                                status['messages'].append({
                                    'role': 'user',
                                    'content': user_message_content,
                                    'timestamp': datetime.now().isoformat()
                                })
                                status['waiting_for_input'] = False
                                
                                if user_message_content.lower() in ["exit", "quit"]:
                                    file_logger.info("ç”¨æˆ·é€€å‡ºå¯¹è¯")
                                    break
                            except queue.Empty:
                                file_logger.warning("ç”¨æˆ·è¾“å…¥è¶…æ—¶")
                                break
                        else:
                            user_message_content = None
                
                except Exception as e:
                    logger.error(f"ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                    file_logger.error(f"ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
                    status['error'] = str(e)
                
                finally:
                    # æ¸…ç†èµ„æº
                    file_logger.info("å¼€å§‹æ¸…ç†èµ„æº...")
                    if agent_id_to_delete and agents_client_for_cleanup:
                        try:
                            await agents_client_for_cleanup.delete_agent(agent_id_to_delete)
                            file_logger.info("âœ“ åŠ©æ‰‹å·²åˆ é™¤")
                        except Exception as e:
                            file_logger.warning(f"âœ— æ— æ³•åˆ é™¤åŠ©æ‰‹: {e}")
                    
                    if thread_id_to_delete and agents_client_for_cleanup:
                        try:
                            await agents_client_for_cleanup.threads.delete(thread_id_to_delete)
                            file_logger.info("âœ“ çº¿ç¨‹å·²åˆ é™¤")
                        except Exception as e:
                            file_logger.warning(f"âœ— æ— æ³•åˆ é™¤çº¿ç¨‹: {e}")
    
    except Exception as e:
        logger.error(f"ç ”ç©¶ä¼šè¯å‘ç”Ÿé”™è¯¯: {e}")
        file_logger.error(f"ç ”ç©¶ä¼šè¯å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        status['error'] = str(e)
    finally:
        status['is_running'] = False
        logger.info("ç ”ç©¶ä¼šè¯ç»“æŸ")
        file_logger.info("ç ”ç©¶ä¼šè¯ç»“æŸ")

def run_research_worker():
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        loop.run_until_complete(run_research_session())
    finally:
        loop.close()

@app.route('/')
def index():
    return render_template('simple_index.html')

@app.route('/api/status')
def get_status():
    return jsonify(status)

@app.route('/api/start_research', methods=['POST'])
def start_research():
    global status
    
    if status['is_running']:
        return jsonify({'error': 'ç ”ç©¶ä¼šè¯å·²åœ¨è¿è¡Œä¸­'}), 400
    
    data = request.get_json()
    topic = data.get('topic', '').strip()
    
    if not topic:
        return jsonify({'error': 'è¯·æä¾›ç ”ç©¶ä¸»é¢˜'}), 400
    
    logger.info(f"å¯åŠ¨æ–°ç ”ç©¶: {topic}")
    
    # é‡ç½®çŠ¶æ€
    status = {
        'is_running': False,
        'messages': [],
        'waiting_for_input': False,
        'error': None,
        'result_file': None
    }
    
    # å‘é€ä¸»é¢˜åˆ°é˜Ÿåˆ—
    message_queue.put(topic)
    
    # å¯åŠ¨ç ”ç©¶çº¿ç¨‹
    research_thread = threading.Thread(target=run_research_worker, daemon=True)
    research_thread.start()
    
    return jsonify({'success': True, 'message': 'ç ”ç©¶ä¼šè¯å·²å¯åŠ¨'})

@app.route('/api/send_message', methods=['POST'])
def send_message():
    global status
    
    if not status['is_running']:
        return jsonify({'error': 'æ²¡æœ‰æ´»è·ƒçš„ç ”ç©¶ä¼šè¯'}), 400
    
    if not status['waiting_for_input']:
        return jsonify({'error': 'å½“å‰ä¸éœ€è¦ç”¨æˆ·è¾“å…¥'}), 400
    
    data = request.get_json()
    message = data.get('message', '').strip()
    
    if not message:
        return jsonify({'error': 'æ¶ˆæ¯ä¸èƒ½ä¸ºç©º'}), 400
    
    logger.info(f"æ”¶åˆ°ç”¨æˆ·æ¶ˆæ¯: {message}")
    
    # å‘é€æ¶ˆæ¯åˆ°é˜Ÿåˆ—
    message_queue.put(message)
    
    return jsonify({'success': True, 'message': 'æ¶ˆæ¯å·²å‘é€'})

@app.route('/api/download/<filename>')
def download_file(filename):
    try:
        logging.getLogger(__name__).info(f"ä¸‹è½½æ–‡ä»¶: {filename}")
        return send_file(filename, as_attachment=True)
    except FileNotFoundError:
        logging.getLogger(__name__).warning(f"æ–‡ä»¶æœªæ‰¾åˆ°: {filename}")
        return jsonify({'error': 'æ–‡ä»¶æœªæ‰¾åˆ°'}), 404

if __name__ == '__main__':
    # åªåœ¨ä¸»è¿›ç¨‹ä¸­æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    print("âœ… é¡¹ç›®é…ç½®ç¯å¢ƒå˜é‡å·²é…ç½®")
    
    if auth_vars_configured:
        print("âœ… ä½¿ç”¨åº”ç”¨æ³¨å†Œå‡­æ®è¿›è¡Œè®¤è¯")
    else:
        print("â„¹ï¸  ä½¿ç”¨ Azure CLI è®¤è¯ï¼ˆè¯·ç¡®ä¿å·²æ‰§è¡Œ 'az login'ï¼‰")
    
    print(f"ğŸ”§ é…ç½®ä¿¡æ¯:")
    print(f"   Project Endpoint: {AZURE_AI_PROJECT_ENDPOINT}")
    print(f"   Bing Connection: {BING_CONNECTION_NAME}")
    print(f"   Research Model: {DEEP_RESEARCH_MODEL}")
    print(f"   Agent Model: {AGENT_MODEL}")
    
    port = int(os.environ.get('PORT', 5000))
    
    print("ğŸ” å¯åŠ¨ Deep Research Web UI...")
    if FLASK_HOST == '127.0.0.1':
        print(f"ğŸ“ æœ¬åœ°è®¿é—®åœ°å€: http://localhost:{port}")
        print(f"ğŸ“ æˆ–è€…è®¿é—®: http://127.0.0.1:{port}")
    else:
        print(f"ğŸ“ è®¿é—®åœ°å€: http://{FLASK_HOST}:{port}")
    print("ğŸ“„ æ—¥å¿—æ–‡ä»¶: " + log_filename)
    print("â¹ï¸  æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    print("-" * 50)
    
    # ç”Ÿäº§ç¯å¢ƒé…ç½®
    app.run(debug=FLASK_DEBUG, host=FLASK_HOST, port=port)